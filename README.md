<h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Requirements" data-toc-modified-id="Requirements-1">Requirements</a></span></li><li><span><a href="#Directory-Tree" data-toc-modified-id="Directory-Tree-2">Directory Tree</a></span></li><li><span><a href="#Data-" data-toc-modified-id="Data--3">Data <a id="data"></a></a></span></li></ul></div>

# Requirements

scikit_optimize==0.7.4 <br>
selenium==3.141.0 <br>
numpy==1.18.1<br>
Keras==2.3.1 <br>
statsmodels==0.11.1<br>
TPOT==0.11.5<br>
dask==2.19.0<br>
Shapely==1.7.0<br>
matplotlib==3.1.2<br>
pandas==1.0.0<br>
wget==3.2<br>
scipy==1.4.1<br>
Fiona==1.8.13<br>
bokeh==2.1.1<br>
pyproj==2.4.2.post1<br>
requests==2.22.0<br>
seaborn==0.10.0<br>
geopandas==0.6.2<br>
swifter==1.0.3<br>
joblib==0.14.1<br>
tqdm==4.43.0<br>
beautifulsoup4==4.9.1<br>
scikit_learn==0.23.2<br>



# Directory Tree

<pre>
├── README.md   
├── requirements.txt : generated by pipreqs
├── data : raw data and processed data for each cities. Please see the [data](#data) section for details about how to obtains the raw data
├── docs : code documentations generated by Sphinx 
├── models : each subfolder contains a model for a each city.  
│   ├──  chiang_mai : contains random forest models for Chiang Mai and model meta file containing setting
│   └── bangkok   
├── reports : plots for each city 
│   ├── chiang_mai : data and model visualizations for Chiang Mai
│   └── bangkok   
├── notebooks   
│   ├── 1_pollutions_data.ipynb : 
│   ├── 1.1_vn_power_plants.ipynb : 
│   ├── 2_analyze_pollution_data.ipynb : 
│   ├── 5.0-ML_Chiang_mai.ipynb : 
│   ├── 6.0_vis_ChiangMai.ipynb : 
│   ├── 6.1_BKK.ipynb : 
│   ├── 6.2_vis_Jarkata.ipynb : 
│   ├── 6.3_Hanoi.ipynb : 
│   └── 7_prediction.ipynb : 
│   
└── src  
    ├── imports.py : 
    ├── gen_functions.py : general purpose functions such as color setting, AQI conversion and coordinate Conversion
    ├── data : download and preprocess data 
    │   ├── download_data.py :  download pollution data from various sources 
    │   ├── read_data.py :  read pollution data 
    │   ├── vn_data.py : scrape pollution data from Vietnamese EPA
    │   ├── weather_data.py : scrape, process and load weather data
    │   └──  fire_data.py : process and load hotspots data
    │     
    ├── features   
    │   ├── build_features.py : 
    │   └── dataset.py : Dataset object is responsible for putting raw data together, 
                         feature engineering and preparing matricies for machine learning models. 
                         Call read_data.py when loading data
                         Call build_features.py for feature engineering functions 
    ├── models   
    │   ├── train_model.py :  model builder and hyperparameter searcher
    │   └── predict_model.py : load model and perform statistical simulations
    │   
    └── visualization  
        ├── vis_data.py : create plots for data exploration steps   
        └── vis_model.py : create plots for visualizing model performance and simulation



# Data <a id='data'></a>


```python

```
