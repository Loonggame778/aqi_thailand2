{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1\">Requirements</a></span></li><li><span><a href=\"#Directory-Tree\" data-toc-modified-id=\"Directory-Tree-2\">Directory Tree</a></span></li><li><span><a href=\"#Data-Sources\" data-toc-modified-id=\"Data-Sources-3\">Data Sources</a></span><ul class=\"toc-item\"><li><span><a href=\"#1-Pollution-Data\" data-toc-modified-id=\"1-Pollution-Data-3.1\">1 Pollution Data</a></span></li><li><span><a href=\"#2.-Weather-Data\" data-toc-modified-id=\"2.-Weather-Data-3.2\">2. Weather Data</a></span></li><li><span><a href=\"#3.-Hotspot-Data\" data-toc-modified-id=\"3.-Hotspot-Data-3.3\">3. Hotspot Data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "numpy==1.18.1<br>\n",
    "matplotlib==3.1.2<br>\n",
    "pandas==1.0.0<br>\n",
    "geopandas==0.6.2<br>\n",
    "scikit_optimize==0.7.4 <br>\n",
    "scikit_learn==0.23.2<br>\n",
    "TPOT==0.11.5<br>\n",
    "statsmodels==0.11.1<br>\n",
    "scipy==1.4.1<br>\n",
    "seaborn==0.10.0<br>\n",
    "joblib==0.14.1<br>\n",
    "tqdm==4.43.0<br>\n",
    "Shapely==1.7.0<br>\n",
    "pyproj==2.4.2.post1<br>\n",
    "Fiona==1.8.13<br>\n",
    "bokeh==2.1.1<br>\n",
    "selenium==3.141.0 <br>\n",
    "wget==3.2<br>\n",
    "beautifulsoup4==4.9.1<br>\n",
    "requests==2.22.0<br>\n",
    "swifter==1.0.3<br>\n",
    "Sphinx>=1.6.0<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "├── README.md   \n",
    "├── requirements.txt : generated by pipreqs\n",
    "├── data : raw data and processed data for each cities. Please see the data section for details about how to obtains the raw data\n",
    "├── docs : code documentations generated by Sphinx \n",
    "├── models : each subfolder contains a model for a each city.  \n",
    "│   ├──  chiang_mai : contains random forest models for Chiang Mai and model meta file containing setting\n",
    "│   └── bangkok   \n",
    "├── reports : plots for each city \n",
    "│   ├── chiang_mai : data and model visualizations for Chiang Mai\n",
    "│   └── bangkok   \n",
    "├── notebooks   \n",
    "│   ├── 1_pollutions_data.ipynb : \n",
    "│   ├── 1.1_vn_power_plants.ipynb : \n",
    "│   ├── 2_analyze_pollution_data.ipynb : \n",
    "│   ├── 5.0-ML_Chiang_mai.ipynb : \n",
    "│   ├── 6.0_vis_ChiangMai.ipynb : \n",
    "│   ├── 6.1_BKK.ipynb : \n",
    "│   ├── 6.2_vis_Jarkata.ipynb : \n",
    "│   ├── 6.3_Hanoi.ipynb : \n",
    "│   └── 7_prediction.ipynb : \n",
    "│   \n",
    "└── src  \n",
    "    ├── imports.py : \n",
    "    ├── gen_functions.py : general purpose functions such as color setting, AQI conversion and coordinate Conversion\n",
    "    ├── data : download and preprocess data \n",
    "    │   ├── download_data.py :  download pollution data from various sources \n",
    "    │   ├── read_data.py :  read pollution data \n",
    "    │   ├── vn_data.py : scrape pollution data from Vietnamese EPA\n",
    "    │   ├── weather_data.py : scrape, process and load weather data\n",
    "    │   └── fire_data.py : process and load hotspots data\n",
    "    │     \n",
    "    ├── features   \n",
    "    │   ├── build_features.py : \n",
    "    │   └── dataset.py : Dataset object is responsible for putting raw data together, \n",
    "    │                    feature engineering and preparing matricies for machine learning models. \n",
    "    │                    Call read_data.py when loading data\n",
    "    │                    Call build_features.py for feature engineering functions \n",
    "    ├── models   \n",
    "    │   ├── train_model.py :  model builder and hyperparameter searcher\n",
    "    │   └── predict_model.py : load model and perform statistical simulations\n",
    "    │   \n",
    "    └── visualization  \n",
    "        ├── vis_data.py : create plots for data exploration steps   \n",
    "        └── vis_model.py : create plots for visualizing model performance and simulation \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Pollution Data\n",
    " - [Thailand EPA](http://air4thai.pcd.go.th/webV2/) Data only go back 2 months! so need to run scapper once a month.\n",
    " - [Berkeley project](http://berkeleyearth.org/) provides historical PM2.5 data back until late 2016 \n",
    " - [The World Air\n",
    "Quality Project](https://aqicn.org/) has pollutions data from many cities, but only provide daily average data  \n",
    "\n",
    "## 2. Weather Data \n",
    "\n",
    "## 3. Hotspot Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
